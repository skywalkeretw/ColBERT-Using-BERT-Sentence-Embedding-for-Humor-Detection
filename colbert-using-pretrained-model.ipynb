{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hi,\n",
    "\n",
    "This is a draft code that loads the pretrained model and predicts a given input. \n",
    "The notebook should run in less than five minutes.\n",
    "\n",
    "Keep in mind that you should download the following folder (my saved model) and put it in the same folder as your code.\n",
    "\n",
    "https://mega.nz/folder/MmB1gIIT#8ilUTK1-BO80aoXxKOIhpg\n",
    "\n",
    "-Moradnejad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /opt/conda/lib/python3.9/site-packages (2.9.0)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.9.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
      "     |████████████████████████████████| 511.7 MB 2.5 kB/s                           | 164.3 MB 29.2 MB/s eta 0:00:12 | 289.0 MB 24.1 MB/s eta 0:00:10\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (1.21.5)\n",
      "Collecting tensorboard<2.10,>=2.9\n",
      "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
      "     |████████████████████████████████| 5.8 MB 32.3 MB/s            \n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.47.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "     |████████████████████████████████| 4.5 MB 30.7 MB/s            \n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.26.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "     |████████████████████████████████| 2.4 MB 16.8 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from tensorflow) (59.8.0)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting flatbuffers<2,>=1.12\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (3.19.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
      "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
      "     |████████████████████████████████| 438 kB 19.4 MB/s            \n",
      "\u001b[?25hCollecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.2.0-py3-none-any.whl (123 kB)\n",
      "     |████████████████████████████████| 123 kB 37.5 MB/s            \n",
      "\u001b[?25hCollecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.14.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
      "     |████████████████████████████████| 77 kB 8.7 MB/s             \n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (3.6.0)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "     |████████████████████████████████| 65 kB 10.4 MB/s            \n",
      "\u001b[?25hCollecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     |████████████████████████████████| 57 kB 13.2 MB/s            \n",
      "\u001b[?25hCollecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "     |████████████████████████████████| 42 kB 3.2 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (4.0.1)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.6-py2.py3-none-manylinux2010_x86_64.whl (14.1 MB)\n",
      "     |████████████████████████████████| 14.1 MB 17.0 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "     |████████████████████████████████| 781 kB 27.5 MB/s            \n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.9.1-py2.py3-none-any.whl (167 kB)\n",
      "     |████████████████████████████████| 167 kB 32.2 MB/s            \n",
      "\u001b[?25hCollecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.2.1-py3-none-any.whl (232 kB)\n",
      "     |████████████████████████████████| 232 kB 30.3 MB/s            \n",
      "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "     |████████████████████████████████| 4.9 MB 14.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.27.1)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "     |████████████████████████████████| 93 kB 1.9 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging->tensorflow) (3.0.6)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "     |████████████████████████████████| 155 kB 28.0 MB/s            \n",
      "\u001b[?25hCollecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.10.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.8)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Downloading MarkupSafe-2.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.7.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "     |████████████████████████████████| 77 kB 14.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.1.1)\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4848 sha256=26c61649f50bf965d3875bdd9a548e8e1024019b3eccbd82c691558def6571f5\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/b6/0d/90/0d1bbd99855f99cb2f6c2e5ff96f8023fad8ec367695f7d72d\n",
      "Successfully built termcolor\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, cachetools, requests-oauthlib, MarkupSafe, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras-preprocessing, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 2.0.1\n",
      "    Uninstalling MarkupSafe-2.0.1:\n",
      "      Successfully uninstalled MarkupSafe-2.0.1\n",
      "Successfully installed MarkupSafe-2.1.1 absl-py-1.2.0 astunparse-1.6.3 cachetools-5.2.0 flatbuffers-1.12 gast-0.4.0 google-auth-2.9.1 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.47.0 keras-preprocessing-1.1.2 libclang-14.0.6 markdown-3.4.1 opt-einsum-3.3.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.9.1 tensorflow-estimator-2.9.0 tensorflow-io-gcs-filesystem-0.26.0 termcolor-1.1.0 werkzeug-2.2.1 wrapt-1.14.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-02 19:19:18.586027: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-02 19:19:18.586088: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-02 19:19:22.099454: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-08-02 19:19:22.099507: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-08-02 19:19:22.099535: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (1966391d240c): /proc/driver/nvidia/version does not exist\n",
      "2022-08-02 19:19:22.099741: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_19 (InputLayer)          [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " input_20 (InputLayer)          [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " input_21 (InputLayer)          [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " input_22 (InputLayer)          [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " input_23 (InputLayer)          [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " input_24 (InputLayer)          [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " input_25 (InputLayer)          [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " input_26 (InputLayer)          [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " input_27 (InputLayer)          [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " input_28 (InputLayer)          [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " input_29 (InputLayer)          [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " input_30 (InputLayer)          [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " input_31 (InputLayer)          [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " input_32 (InputLayer)          [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " input_33 (InputLayer)          [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " input_34 (InputLayer)          [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " input_35 (InputLayer)          [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " input_36 (InputLayer)          [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " bert (Custom>TFBertMainLayer)  multiple             109482240   ['input_19[0][0]',               \n",
      "                                                                  'input_20[0][0]',               \n",
      "                                                                  'input_21[0][0]',               \n",
      "                                                                  'input_22[0][0]',               \n",
      "                                                                  'input_23[0][0]',               \n",
      "                                                                  'input_24[0][0]',               \n",
      "                                                                  'input_25[0][0]',               \n",
      "                                                                  'input_26[0][0]',               \n",
      "                                                                  'input_27[0][0]',               \n",
      "                                                                  'input_28[0][0]',               \n",
      "                                                                  'input_29[0][0]',               \n",
      "                                                                  'input_30[0][0]',               \n",
      "                                                                  'input_31[0][0]',               \n",
      "                                                                  'input_32[0][0]',               \n",
      "                                                                  'input_33[0][0]',               \n",
      "                                                                  'input_34[0][0]',               \n",
      "                                                                  'input_35[0][0]',               \n",
      "                                                                  'input_36[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling1d_6 (Gl  (None, 768)         0           ['bert[0][0]']                   \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_7 (Gl  (None, 768)         0           ['bert[1][0]']                   \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_8 (Gl  (None, 768)         0           ['bert[2][0]']                   \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_9 (Gl  (None, 768)         0           ['bert[3][0]']                   \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_10 (G  (None, 768)         0           ['bert[4][0]']                   \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_11 (G  (None, 768)         0           ['bert[5][0]']                   \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 32)           24608       ['global_average_pooling1d_6[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 32)           24608       ['global_average_pooling1d_7[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 32)           24608       ['global_average_pooling1d_8[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 32)           24608       ['global_average_pooling1d_9[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 32)           24608       ['global_average_pooling1d_10[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 256)          196864      ['global_average_pooling1d_11[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_44 (Dropout)           (None, 32)           0           ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_45 (Dropout)           (None, 32)           0           ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_46 (Dropout)           (None, 32)           0           ['dense_19[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_47 (Dropout)           (None, 32)           0           ['dense_21[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_48 (Dropout)           (None, 32)           0           ['dense_23[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_49 (Dropout)           (None, 256)          0           ['dense_25[0][0]']               \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 8)            264         ['dropout_44[0][0]']             \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 8)            264         ['dropout_45[0][0]']             \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 8)            264         ['dropout_46[0][0]']             \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 8)            264         ['dropout_47[0][0]']             \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 8)            264         ['dropout_48[0][0]']             \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 64)           16448       ['dropout_49[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 104)          0           ['dense_16[0][0]',               \n",
      "                                                                  'dense_18[0][0]',               \n",
      "                                                                  'dense_20[0][0]',               \n",
      "                                                                  'dense_22[0][0]',               \n",
      "                                                                  'dense_24[0][0]',               \n",
      "                                                                  'dense_26[0][0]']               \n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, 512)          53760       ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_50 (Dropout)           (None, 512)          0           ['dense_27[0][0]']               \n",
      "                                                                                                  \n",
      " dense_28 (Dense)               (None, 256)          131328      ['dropout_50[0][0]']             \n",
      "                                                                                                  \n",
      " dense_29 (Dense)               (None, 1)            257         ['dense_28[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 110,005,257\n",
      "Trainable params: 110,005,257\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n",
    "!pip install tensorflow\n",
    "import keras\n",
    "\n",
    "model = keras.models.load_model(\"colbert-trained/\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# complete code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "papermill": {
     "duration": 0.079797,
     "end_time": "2021-03-29T08:43:02.130587",
     "exception": false,
     "start_time": "2021-03-29T08:43:02.05079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# CPU\n",
      "model name\t: Intel(R) Core(TM) i9-9980HK CPU @ 2.40GHz\n",
      "cpu MHz\t\t: 2400.000\n",
      "cpu cores\t: 1\n",
      "# RAM\n",
      "MemTotal:       28757784 kB\n",
      "# GPU\n",
      "\n",
      "# OS\n",
      "Linux 1966391d240c 5.10.25-linuxkit #1 SMP Tue Mar 23 09:27:39 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: lspci: not found\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "from ast import literal_eval\n",
    "\n",
    "def run(command):\n",
    "    process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE)\n",
    "    out, err = process.communicate()\n",
    "    print(out.decode('utf-8').strip())\n",
    "\n",
    "print('# CPU')\n",
    "run('cat /proc/cpuinfo | egrep -m 1 \"^model name\"')\n",
    "run('cat /proc/cpuinfo | egrep -m 1 \"^cpu MHz\"')\n",
    "run('cat /proc/cpuinfo | egrep -m 1 \"^cpu cores\"')\n",
    "\n",
    "print('# RAM')\n",
    "run('cat /proc/meminfo | egrep \"^MemTotal\"')\n",
    "\n",
    "print('# GPU')\n",
    "run('lspci | grep VGA')\n",
    "\n",
    "print('# OS')\n",
    "run('uname -a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "papermill": {
     "duration": 9.528184,
     "end_time": "2021-03-29T08:43:11.678854",
     "exception": false,
     "start_time": "2021-03-29T08:43:02.15067",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.21.0-py3-none-any.whl (4.7 MB)\n",
      "     |████████████████████████████████| 4.7 MB 5.5 MB/s            \n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
      "     |████████████████████████████████| 101 kB 22.1 MB/s           \n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from transformers) (1.21.5)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.7.1-py3-none-any.whl (10 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "     |████████████████████████████████| 6.6 MB 13.2 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from transformers) (4.62.3)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2022.7.25-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (765 kB)\n",
      "     |████████████████████████████████| 765 kB 32.3 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (2.0.10)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (3.3)\n",
      "Installing collected packages: filelock, tokenizers, regex, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.7.1 huggingface-hub-0.8.1 regex-2022.7.25 tokenizers-0.12.1 transformers-4.21.0\n",
      "2.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "# import bert_tokenization as tokenization\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow import keras \n",
    "\n",
    "import os\n",
    "from scipy.stats import spearmanr\n",
    "from math import floor, ceil\n",
    "from transformers import *\n",
    "\n",
    "import seaborn as sns\n",
    "import string\n",
    "import re    #for regex\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019612,
     "end_time": "2021-03-29T08:43:11.7194",
     "exception": false,
     "start_time": "2021-03-29T08:43:11.699788",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prep / tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019527,
     "end_time": "2021-03-29T08:43:11.758635",
     "exception": false,
     "start_time": "2021-03-29T08:43:11.739108",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 1. Read data and tokenizer\n",
    "\n",
    "Read tokenizer and data, as well as defining the maximum sequence length that will be used for the input to Bert (maximum is usually 512 tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "papermill": {
     "duration": 0.030283,
     "end_time": "2021-03-29T08:43:11.808497",
     "exception": false,
     "start_time": "2021-03-29T08:43:11.778214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_sample_count = 1000 # 4000\n",
    "test_count = 1000\n",
    "\n",
    "MAX_SENTENCE_LENGTH = 20\n",
    "MAX_SENTENCES = 5\n",
    "MAX_LENGTH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "papermill": {
     "duration": 0.698464,
     "end_time": "2021-03-29T08:43:12.526679",
     "exception": false,
     "start_time": "2021-03-29T08:43:11.828215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/kaggle/input/200k-short-texts-for-humor-detection': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle/input/200k-short-texts-for-humor-detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020423,
     "end_time": "2021-03-29T08:43:12.568031",
     "exception": false,
     "start_time": "2021-03-29T08:43:12.547608",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "papermill": {
     "duration": 0.818548,
     "end_time": "2021-03-29T08:43:13.406935",
     "exception": false,
     "start_time": "2021-03-29T08:43:12.588387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>humor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joe biden rules out 2020 bid: 'guys, i'm not r...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Watch: darvish gave hitter whiplash with slow ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What do you call a turtle without its shell? d...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  humor\n",
       "0  Joe biden rules out 2020 bid: 'guys, i'm not r...  False\n",
       "1  Watch: darvish gave hitter whiplash with slow ...  False\n",
       "2  What do you call a turtle without its shell? d...   True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>humor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What kind of cat should you take into the  des...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Remember when people used to have to be in sha...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pizza is always good. - everyone we'll see abo...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  humor\n",
       "0  What kind of cat should you take into the  des...   True\n",
       "1  Remember when people used to have to be in sha...   True\n",
       "2  Pizza is always good. - everyone we'll see abo...   True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df = pd.read_csv('/kaggle/input/200k-short-texts-for-humor-detection/dataset.csv')\n",
    "df = pd.read_csv('Data/dataset.csv')\n",
    "\n",
    "# df_train = pd.read_csv('/kaggle/input/200k-short-texts-for-humor-detection/train.csv')\n",
    "df_train = pd.read_csv('Data/train.csv')\n",
    "display(df_train.head(3))\n",
    "df_train = df_train[:training_sample_count]\n",
    "\n",
    "# df_test = pd.read_csv('/kaggle/input/200k-short-texts-for-humor-detection/dev.csv')\n",
    "df_test = pd.read_csv('Data/dev.csv')\n",
    "display(df_test.head(3))\n",
    "df_test = df_test[:test_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "papermill": {
     "duration": 0.04181,
     "end_time": "2021-03-29T08:43:13.470207",
     "exception": false,
     "start_time": "2021-03-29T08:43:13.428397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000 1000 1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>humor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joe biden rules out 2020 bid: 'guys, i'm not r...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Watch: darvish gave hitter whiplash with slow ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What do you call a turtle without its shell? d...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 reasons the 2016 election feels so personal</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pasco police shot mexican migrant from behind,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  humor\n",
       "0  Joe biden rules out 2020 bid: 'guys, i'm not r...  False\n",
       "1  Watch: darvish gave hitter whiplash with slow ...  False\n",
       "2  What do you call a turtle without its shell? d...   True\n",
       "3      5 reasons the 2016 election feels so personal  False\n",
       "4  Pasco police shot mexican migrant from behind,...  False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What kind of cat should you take into the  des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Remember when people used to have to be in sha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pizza is always good. - everyone we'll see abo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What's 6 inches long hard, bent, and in my pan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Black teen's response to violence in his commu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  What kind of cat should you take into the  des...\n",
       "1  Remember when people used to have to be in sha...\n",
       "2  Pizza is always good. - everyone we'll see abo...\n",
       "3  What's 6 inches long hard, bent, and in my pan...\n",
       "4  Black teen's response to violence in his commu..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df_y = df_test.copy()\n",
    "del df_test['humor']\n",
    "\n",
    "df_sub = test_df_y.copy()\n",
    "\n",
    "print(len(df),len(df_train),len(df_test))\n",
    "display(df_train.head())\n",
    "display(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "papermill": {
     "duration": 0.031866,
     "end_time": "2021-03-29T08:43:13.525141",
     "exception": false,
     "start_time": "2021-03-29T08:43:13.493275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text', 'humor']\n"
     ]
    }
   ],
   "source": [
    "print(list(df_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "papermill": {
     "duration": 0.034743,
     "end_time": "2021-03-29T08:43:13.583166",
     "exception": false,
     "start_time": "2021-03-29T08:43:13.548423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "input categories:\n",
      "\t ['text']\n",
      "\n",
      "output TARGET_COUNT:\n",
      "\t 1\n",
      "\n",
      "output categories:\n",
      "\t ['humor']\n"
     ]
    }
   ],
   "source": [
    "output_categories = list(df_train.columns[[1]])\n",
    "input_categories = list(df_train.columns[[0]])\n",
    "\n",
    "TARGET_COUNT = len(output_categories)\n",
    "\n",
    "print('\\ninput categories:\\n\\t', input_categories)\n",
    "print('\\noutput TARGET_COUNT:\\n\\t', TARGET_COUNT)\n",
    "print('\\noutput categories:\\n\\t', output_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023995,
     "end_time": "2021-03-29T08:43:13.630641",
     "exception": false,
     "start_time": "2021-03-29T08:43:13.606646",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Preprocessing functions\n",
    "\n",
    "These are some functions that will be used to preprocess the raw text data into useable Bert inputs.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "papermill": {
     "duration": 0.252597,
     "end_time": "2021-03-29T08:43:13.907097",
     "exception": false,
     "start_time": "2021-03-29T08:43:13.6545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/jovyan/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/jovyan/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/jovyan/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "MODEL_TYPE = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "papermill": {
     "duration": 0.584315,
     "end_time": "2021-03-29T08:43:14.516208",
     "exception": false,
     "start_time": "2021-03-29T08:43:13.931893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.9/site-packages (3.7)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.9/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.9/site-packages (from nltk) (2022.7.25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "papermill": {
     "duration": 0.04248,
     "end_time": "2021-03-29T08:43:14.583771",
     "exception": false,
     "start_time": "2021-03-29T08:43:14.541291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def return_id(str1, str2, truncation_strategy, length):\n",
    "\n",
    "    inputs = tokenizer.encode_plus(str1, str2,\n",
    "        add_special_tokens=True,\n",
    "        max_length=length,\n",
    "        truncation_strategy=truncation_strategy)\n",
    "\n",
    "    input_ids =  inputs[\"input_ids\"]\n",
    "    input_masks = [1] * len(input_ids)\n",
    "    input_segments = inputs[\"token_type_ids\"]\n",
    "    padding_length = length - len(input_ids)\n",
    "    padding_id = tokenizer.pad_token_id\n",
    "    input_ids = input_ids + ([padding_id] * padding_length)\n",
    "    input_masks = input_masks + ([0] * padding_length)\n",
    "    input_segments = input_segments + ([0] * padding_length)\n",
    "\n",
    "    return [input_ids, input_masks, input_segments]\n",
    "\n",
    "\n",
    "def compute_input_arrays(df, columns, tokenizer):\n",
    "    model_input = []\n",
    "    for xx in range((MAX_SENTENCES*3)+3):\n",
    "        model_input.append([])\n",
    "    \n",
    "    for _, row in tqdm(df[columns].iterrows()):\n",
    "        i = 0\n",
    "        \n",
    "        # sent\n",
    "        sentences = sent_tokenize(row.text)\n",
    "        for xx in range(MAX_SENTENCES):\n",
    "            s = sentences[xx] if xx<len(sentences) else ''\n",
    "            ids_q, masks_q, segments_q = return_id(s, None, 'longest_first', MAX_SENTENCE_LENGTH)\n",
    "            model_input[i].append(ids_q)\n",
    "            i+=1\n",
    "            model_input[i].append(masks_q)\n",
    "            i+=1\n",
    "            model_input[i].append(segments_q)\n",
    "            i+=1\n",
    "        \n",
    "        # full row\n",
    "        ids_q, masks_q, segments_q = return_id(row.text, None, 'longest_first', MAX_LENGTH)\n",
    "        model_input[i].append(ids_q)\n",
    "        i+=1\n",
    "        model_input[i].append(masks_q)\n",
    "        i+=1\n",
    "        model_input[i].append(segments_q)\n",
    "        \n",
    "    for xx in range((MAX_SENTENCES*3)+3):\n",
    "        model_input[xx] = np.asarray(model_input[xx], dtype=np.int32)\n",
    "        \n",
    "    print(model_input[0].shape)\n",
    "    return model_input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "papermill": {
     "duration": 387.845343,
     "end_time": "2021-03-29T08:49:42.485726",
     "exception": false,
     "start_time": "2021-03-29T08:43:14.640383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9f0b5c39c3f4d28b724738503e8d901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cdaab90ed4d431180b3d05ca8393f91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20)\n"
     ]
    }
   ],
   "source": [
    "inputs      = compute_input_arrays(df_train, input_categories, tokenizer)\n",
    "test_inputs = compute_input_arrays(df_test, input_categories, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "papermill": {
     "duration": 0.047335,
     "end_time": "2021-03-29T08:49:42.56236",
     "exception": false,
     "start_time": "2021-03-29T08:49:42.515025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 1000 20\n",
      "Why do native americans hate it when it rains in april? because it brings mayflowers.\n",
      "['Why do native americans hate it when it rains in april?', 'because it brings mayflowers.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([  101,  2339,  2079,  3128,  4841,  5223,  2009,  2043,  2009,\n",
       "        15811,  1999,  2258,  1029,   102,     0,     0,     0,     0,\n",
       "            0,     0], dtype=int32),\n",
       " array([  101,  2138,  2009,  7545,  2089, 14156,  2015,  1012,   102,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0], dtype=int32),\n",
       " array([101, 102,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0], dtype=int32),\n",
       " array([  101,  2339,  2079,  3128,  4841,  5223,  2009,  2043,  2009,\n",
       "        15811,  1999,  2258,  1029,  2138,  2009,  7545,  2089, 14156,\n",
       "         2015,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0], dtype=int32))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(inputs), len(inputs[0]), len(inputs[0][0]))\n",
    "\n",
    "# check out input for 7th row\n",
    "xx = 7\n",
    "print(df_train.iloc[xx,0])\n",
    "print(sent_tokenize(df_train.iloc[xx,0]))\n",
    "inputs[0][xx], inputs[3][xx], inputs[6][xx], inputs[15][xx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "papermill": {
     "duration": 0.040866,
     "end_time": "2021-03-29T08:49:42.634025",
     "exception": false,
     "start_time": "2021-03-29T08:49:42.593159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_output_arrays(df, columns):\n",
    "    return np.asarray(df[columns])\n",
    "\n",
    "outputs = compute_output_arrays(df_train, output_categories)\n",
    "outputs[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.040148,
     "end_time": "2021-03-29T08:50:18.903097",
     "exception": false,
     "start_time": "2021-03-29T08:50:18.862949",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. Training, validation and testing\n",
    "\n",
    "Loops over the folds in gkf and trains each fold for 3 epochs --- with a learning rate of 3e-5 and batch_size of 6. A simple binary crossentropy is used as the objective-/loss-function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "papermill": {
     "duration": 0.073314,
     "end_time": "2021-03-29T08:50:19.013676",
     "exception": false,
     "start_time": "2021-03-29T08:50:18.940362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== \n",
      "mean_absolute_error  : 0.09999999999999999\n",
      "mean_squared_error  : 0.009999999999999998\n",
      "r2 score  : 0.96\n",
      "================== \n",
      "f1_score  : 0.6666666666666666\n",
      "[[0 1]\n",
      " [0 1]]\n",
      "Acc 0.5 Prec 0.5 Rec 1.0 F1 0.6666666666666666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation Metrics\n",
    "import sklearn\n",
    "def print_evaluation_metrics(y_true, y_pred, label='', is_regression=True, label2=''):\n",
    "    print('==================', label2)\n",
    "    ### For regression\n",
    "    if is_regression:\n",
    "        print('mean_absolute_error',label,':', sklearn.metrics.mean_absolute_error(y_true, y_pred))\n",
    "        print('mean_squared_error',label,':', sklearn.metrics.mean_squared_error(y_true, y_pred))\n",
    "        print('r2 score',label,':', sklearn.metrics.r2_score(y_true, y_pred))\n",
    "        #     print('max_error',label,':', sklearn.metrics.max_error(y_true, y_pred))\n",
    "        return sklearn.metrics.mean_squared_error(y_true, y_pred)\n",
    "    else:\n",
    "        ### FOR Classification\n",
    "#         print('balanced_accuracy_score',label,':', sklearn.metrics.balanced_accuracy_score(y_true, y_pred))\n",
    "#         print('average_precision_score',label,':', sklearn.metrics.average_precision_score(y_true, y_pred))\n",
    "#         print('balanced_accuracy_score',label,':', sklearn.metrics.balanced_accuracy_score(y_true, y_pred))\n",
    "#         print('accuracy_score',label,':', sklearn.metrics.accuracy_score(y_true, y_pred))\n",
    "        print('f1_score',label,':', sklearn.metrics.f1_score(y_true, y_pred))\n",
    "        \n",
    "        matrix = sklearn.metrics.confusion_matrix(y_true, y_pred)\n",
    "        print(matrix)\n",
    "        TP,TN,FP,FN = matrix[1][1],matrix[0][0],matrix[0][1],matrix[1][0]\n",
    "        Accuracy = (TP+TN)/(TP+FP+FN+TN)\n",
    "        Precision = TP/(TP+FP)\n",
    "        Recall = TP/(TP+FN)\n",
    "        F1 = 2*(Recall * Precision) / (Recall + Precision)\n",
    "        print('Acc', Accuracy, 'Prec', Precision, 'Rec', Recall, 'F1',F1)\n",
    "        return sklearn.metrics.accuracy_score(y_true, y_pred)\n",
    "\n",
    "print_evaluation_metrics([1,0], [0.9,0.1], '', True)\n",
    "print_evaluation_metrics([1,0], [1,1], '', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.038588,
     "end_time": "2021-03-29T08:50:19.090696",
     "exception": false,
     "start_time": "2021-03-29T08:50:19.052108",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Loss function selection\n",
    "Regression problem between 0 and 1, so binary_crossentropy and mean_absolute_error seem good.\n",
    "\n",
    "Here are the explanations: https://www.dlology.com/blog/how-to-choose-last-layer-activation-and-loss-function/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_inputs = inputs\n",
    "valid_outputs = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 126s 4s/step\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(valid_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "papermill": {
     "duration": 9.430336,
     "end_time": "2021-03-29T11:57:41.18514",
     "exception": false,
     "start_time": "2021-03-29T11:57:31.754804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "papermill": {
     "duration": 9.363135,
     "end_time": "2021-03-29T11:58:00.380535",
     "exception": false,
     "start_time": "2021-03-29T11:57:51.0174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1) (1000, 1)\n",
      "================== \n",
      "mean_absolute_error  : 0.008370925\n",
      "mean_squared_error  : 0.005929642\n",
      "r2 score  : 0.9762767811032094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.005929642"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(valid_outputs.shape, preds.shape)\n",
    "print_evaluation_metrics(np.array(valid_outputs), np.array(preds), '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 136s 4s/step\n"
     ]
    }
   ],
   "source": [
    "test_preds = model.predict(test_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 9.331535,
     "end_time": "2021-03-29T12:04:44.212433",
     "exception": false,
     "start_time": "2021-03-29T12:04:34.880898",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Binary submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "papermill": {
     "duration": 12.111,
     "end_time": "2021-03-29T12:05:06.339173",
     "exception": false,
     "start_time": "2021-03-29T12:04:54.228173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== SPLIT on 0.1\n",
      "f1_score  : 0.9769673704414588\n",
      "[[467  17]\n",
      " [  7 509]]\n",
      "Acc 0.976 Prec 0.967680608365019 Rec 0.9864341085271318 F1 0.9769673704414588\n",
      "================== SPLIT on 0.2\n",
      "f1_score  : 0.9797492767598842\n",
      "[[471  13]\n",
      " [  8 508]]\n",
      "Acc 0.979 Prec 0.9750479846449136 Rec 0.9844961240310077 F1 0.9797492767598842\n",
      "================== SPLIT on 0.30000000000000004\n",
      "f1_score  : 0.9816069699903194\n",
      "[[474  10]\n",
      " [  9 507]]\n",
      "Acc 0.981 Prec 0.9806576402321083 Rec 0.9825581395348837 F1 0.9816069699903194\n",
      "================== SPLIT on 0.4\n",
      "f1_score  : 0.9825581395348837\n",
      "[[475   9]\n",
      " [  9 507]]\n",
      "Acc 0.982 Prec 0.9825581395348837 Rec 0.9825581395348837 F1 0.9825581395348837\n",
      "================== SPLIT on 0.5\n",
      "f1_score  : 0.9835111542192047\n",
      "[[476   8]\n",
      " [  9 507]]\n",
      "Acc 0.983 Prec 0.9844660194174757 Rec 0.9825581395348837 F1 0.9835111542192047\n",
      "================== SPLIT on 0.6\n",
      "f1_score  : 0.9825242718446603\n",
      "[[476   8]\n",
      " [ 10 506]]\n",
      "Acc 0.982 Prec 0.9844357976653697 Rec 0.9806201550387597 F1 0.9825242718446603\n",
      "================== SPLIT on 0.7000000000000001\n",
      "f1_score  : 0.9815354713313897\n",
      "[[476   8]\n",
      " [ 11 505]]\n",
      "Acc 0.981 Prec 0.9844054580896686 Rec 0.9786821705426356 F1 0.9815354713313897\n",
      "================== SPLIT on 0.8\n",
      "f1_score  : 0.980544747081712\n",
      "[[476   8]\n",
      " [ 12 504]]\n",
      "Acc 0.98 Prec 0.984375 Rec 0.9767441860465116 F1 0.980544747081712\n",
      "================== SPLIT on 0.9\n",
      "f1_score  : 0.9814634146341463\n",
      "[[478   6]\n",
      " [ 13 503]]\n",
      "Acc 0.981 Prec 0.9882121807465619 Rec 0.9748062015503876 F1 0.9814634146341463\n"
     ]
    }
   ],
   "source": [
    "for split in np.arange(0.1, 0.99, 0.1).tolist():\n",
    "    df_sub['pred_bi'] = (test_preds > split)\n",
    "\n",
    "    print_evaluation_metrics(df_sub['humor'], df_sub['pred_bi'], '', False, 'SPLIT on '+str(split))\n",
    "\n",
    "    df_sub.to_csv('sub3.csv', index=False)\n",
    "    df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "papermill": {
     "duration": 10.02187,
     "end_time": "2021-03-29T12:05:25.894599",
     "exception": false,
     "start_time": "2021-03-29T12:05:15.872729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== SPLIT on 0.9\n",
      "f1_score  : 0.9835111542192047\n",
      "[[476   8]\n",
      " [  9 507]]\n",
      "Acc 0.983 Prec 0.9844660194174757 Rec 0.9825581395348837 F1 0.9835111542192047\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>humor</th>\n",
       "      <th>pred_bi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What kind of cat should you take into the  des...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Remember when people used to have to be in sha...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pizza is always good. - everyone we'll see abo...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What's 6 inches long hard, bent, and in my pan...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Black teen's response to violence in his commu...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  humor  pred_bi\n",
       "0  What kind of cat should you take into the  des...   True     True\n",
       "1  Remember when people used to have to be in sha...   True     True\n",
       "2  Pizza is always good. - everyone we'll see abo...   True     True\n",
       "3  What's 6 inches long hard, bent, and in my pan...   True     True\n",
       "4  Black teen's response to violence in his commu...  False    False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub['pred_bi'] = (test_preds > 0.5)\n",
    "\n",
    "print_evaluation_metrics(df_sub['humor'], df_sub['pred_bi'], '', False, 'SPLIT on '+str(split))\n",
    "\n",
    "df_sub.to_csv('sub.csv', index=False)\n",
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "papermill": {
     "duration": 9.253716,
     "end_time": "2021-03-29T12:05:44.483167",
     "exception": false,
     "start_time": "2021-03-29T12:05:35.229451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts that the model failed to correctly predict:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>humor</th>\n",
       "      <th>pred_bi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>Ariana grande looks like she was designed in a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>If you're happy and you know it, share your meds</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>Friends don't let friends make harlem shake' v...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>The whip was especially popular in the 1800's</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>One out of five dentists has the courage to sp...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>New subway slogan idea from jared 12 is the ne...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>The easiest way to water plants is...using a t...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>What is this 'wrong hole' you people speak of?</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>What happens when you retweet a compliment abo...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>The boomerang is australia's chief export (and...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>Who's in charge? are you a wimpy parent?</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>Weed is out of the bag... what's next? how soon?</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>Try to keep calm but k-pop band bts is getting...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>Netanyahu is an ass, but he's my ass</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>Fighter. liberator. ungovernable woman. mother...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>What if everyone had only one true soul mate, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>These are our relationships as depicted by foo...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  humor  pred_bi\n",
       "252  Ariana grande looks like she was designed in a...   True    False\n",
       "303   If you're happy and you know it, share your meds   True    False\n",
       "309  Friends don't let friends make harlem shake' v...   True    False\n",
       "310      The whip was especially popular in the 1800's   True    False\n",
       "345  One out of five dentists has the courage to sp...   True    False\n",
       "361  New subway slogan idea from jared 12 is the ne...   True    False\n",
       "372  The easiest way to water plants is...using a t...  False     True\n",
       "383     What is this 'wrong hole' you people speak of?   True    False\n",
       "525  What happens when you retweet a compliment abo...   True    False\n",
       "572  The boomerang is australia's chief export (and...   True    False\n",
       "587           Who's in charge? are you a wimpy parent?  False     True\n",
       "628   Weed is out of the bag... what's next? how soon?  False     True\n",
       "714  Try to keep calm but k-pop band bts is getting...  False     True\n",
       "812               Netanyahu is an ass, but he's my ass  False     True\n",
       "878  Fighter. liberator. ungovernable woman. mother...  False     True\n",
       "883  What if everyone had only one true soul mate, ...  False     True\n",
       "987  These are our relationships as depicted by foo...  False     True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Texts that the model failed to correctly predict:')\n",
    "df_sub[df_sub['pred_bi']!=df_sub['humor']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
